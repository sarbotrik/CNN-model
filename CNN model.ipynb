{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de0056d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1984bc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[171 137 138]\n",
      "  [171 137 138]\n",
      "  [171 137 138]\n",
      "  ...\n",
      "  [179 146 137]\n",
      "  [181 145 137]\n",
      "  [184 148 140]]\n",
      "\n",
      " [[171 137 138]\n",
      "  [172 138 139]\n",
      "  [172 138 139]\n",
      "  ...\n",
      "  [177 143 137]\n",
      "  [180 144 138]\n",
      "  [183 147 141]]\n",
      "\n",
      " [[170 138 139]\n",
      "  [170 138 139]\n",
      "  [170 137 141]\n",
      "  ...\n",
      "  [186 151 147]\n",
      "  [182 147 143]\n",
      "  [178 143 139]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 23  19  30]\n",
      "  [ 24  20  31]\n",
      "  [ 22  22  34]\n",
      "  ...\n",
      "  [ 48  43  42]\n",
      "  [ 43  38  37]\n",
      "  [ 40  35  34]]\n",
      "\n",
      " [[ 23  25  25]\n",
      "  [ 23  27  28]\n",
      "  [ 23  28  31]\n",
      "  ...\n",
      "  [ 40  35  32]\n",
      "  [ 39  34  31]\n",
      "  [ 39  34  31]]\n",
      "\n",
      " [[ 20  26  21]\n",
      "  [ 21  28  25]\n",
      "  [ 22  28  27]\n",
      "  ...\n",
      "  [ 46  41  38]\n",
      "  [ 49  44  41]\n",
      "  [ 51  46  43]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 150, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=cv2.imread(r\"D:\\image classification\\seg_pred\\seg_pred\\5.jpg\")\n",
    "print(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e0027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=ImageDataGenerator(1/255)\n",
    "test=ImageDataGenerator(1/255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9faef88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset=train.flow_from_directory(r\"D:\\image classification\\seg_train\\seg_train\", target_size=(150,150), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2f4387e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_dataset=test.flow_from_directory(r\"D:\\image classification\\seg_test\\seg_test\", target_size=(150,150), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7e25a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buildings': 0,\n",
       " 'forest': 1,\n",
       " 'glacier': 2,\n",
       " 'mountain': 3,\n",
       " 'sea': 4,\n",
       " 'street': 5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44ab7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation='relu', input_shape=(150,150,3)),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(6)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c02f4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8f5ea85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "439/439 [==============================] - 531s 1s/step - loss: 10.4719 - accuracy: 0.1785 - val_loss: 10.6057 - val_accuracy: 0.1750\n",
      "Epoch 2/10\n",
      "439/439 [==============================] - 496s 1s/step - loss: 10.4973 - accuracy: 0.1790 - val_loss: 10.6057 - val_accuracy: 0.1750\n",
      "Epoch 3/10\n",
      "439/439 [==============================] - 510s 1s/step - loss: 10.4973 - accuracy: 0.1790 - val_loss: 10.6057 - val_accuracy: 0.1750\n",
      "Epoch 4/10\n",
      "439/439 [==============================] - 512s 1s/step - loss: 10.4973 - accuracy: 0.1790 - val_loss: 10.6057 - val_accuracy: 0.1750\n",
      "Epoch 5/10\n",
      "439/439 [==============================] - 522s 1s/step - loss: 10.4973 - accuracy: 0.1790 - val_loss: 10.6057 - val_accuracy: 0.1750\n",
      "Epoch 6/10\n",
      "439/439 [==============================] - 698s 2s/step - loss: 10.4973 - accuracy: 0.1790 - val_loss: 10.6057 - val_accuracy: 0.1750\n",
      "Epoch 7/10\n",
      "439/439 [==============================] - 7939s 18s/step - loss: 10.4973 - accuracy: 0.1790 - val_loss: 10.6057 - val_accuracy: 0.1750\n",
      "Epoch 8/10\n",
      "439/439 [==============================] - 532s 1s/step - loss: 10.4973 - accuracy: 0.1790 - val_loss: 10.6057 - val_accuracy: 0.1750\n",
      "Epoch 9/10\n",
      "439/439 [==============================] - 520s 1s/step - loss: 10.4973 - accuracy: 0.1790 - val_loss: 10.6057 - val_accuracy: 0.1750\n",
      "Epoch 10/10\n",
      "439/439 [==============================] - 524s 1s/step - loss: 10.4973 - accuracy: 0.1790 - val_loss: 10.6057 - val_accuracy: 0.1750\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_dataset, epochs=10, validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c71265d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca81207f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573290ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
